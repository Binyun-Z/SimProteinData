{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用ESM预训练模型提取特征向量\n",
    "参考：https://github.com/facebookresearch/esm/blob/c9c7d4f0fec964ce10c3e11dccec6c16edaa5144/scripts/extract.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binyun/miniforge3/envs/esm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import EsmForMaskedLM, EsmTokenizer, EsmModel\n",
    "from esm import Alphabet, FastaBatchedDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinExtractionParams:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model='ESM-1b',\n",
    "        EMB_LAYER = 33,\n",
    "        model_seed = 1,\n",
    "        fasta_file = None,\n",
    "        csv_file = '../data/DMS_substitutions.csv',\n",
    "\n",
    "        batch_size=32,\n",
    "        repr_layers=[-1],\n",
    "        include='mean',\n",
    "        truncation_seq_length=1022,\n",
    "        nogpu=False,\n",
    "    ):\n",
    "        self.model=model\n",
    "        self.model_seed = model_seed\n",
    "        self.EMB_LAYER = EMB_LAYER\n",
    "        self.fasta_file = fasta_file\n",
    "        self.csv_file = csv_file\n",
    "        self.batch_size = batch_size\n",
    "        self.repr_layers = repr_layers\n",
    "        self.include = include\n",
    "        self.truncation_seq_length = truncation_seq_length\n",
    "        self.nogpu = nogpu\n",
    "        self.save_path = csv_file.split('.csv')[0]+'esm_embed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = ProteinExtractionParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protein_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, sep_len=1022):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = sep_len\n",
    "        self.seq, self.attention_mask = tokenizer(list(self.df['target_seq']), padding='max_length',\n",
    "                                                  truncation=True,\n",
    "                                                  max_length=self.seq_len).values()\n",
    "        self.DMS_id = np.asarray(df['DMS_id'])\n",
    "        self.pid = np.asarray(df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.seq[idx], self.attention_mask[idx],self.DMS_id[idx],self.pid[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        seq = torch.tensor(np.array([u[0] for u in data]))\n",
    "        att_mask = torch.tensor(np.array([u[1] for u in data]))\n",
    "        DMS_id = [u[2] for u in data]\n",
    "        pid = torch.tensor(np.array([u[3] for u in data]))\n",
    "        return seq, att_mask, DMS_id,pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(model,data_loader,save_path,repr_layers=33,return_contacts=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(data_loader):\n",
    "\n",
    "            seq, mask, DMS_id,pid= data[0],data[1],data[2],data[3]\n",
    "            print(\n",
    "                f\"Processing {batch_idx + 1} of {len(data)} batches ({seq.size(0)} sequences)\"\n",
    "            )\n",
    "            if torch.cuda.is_available() and not config.nogpu:\n",
    "                seq = seq.to(device=\"cuda\", non_blocking=True)\n",
    "                mask = mask.to(device=\"cuda\", non_blocking=True)\n",
    "\n",
    "            out = model(seq,mask)\n",
    "            # print(out.last_hidden_state.mean(dim=1).shape)\n",
    "            # print(out.pooler_output.shape)\n",
    "            batch_representations = out.pooler_output\n",
    "            for index,dms in enumerate(DMS_id):\n",
    "                representations = batch_representations[index]\n",
    "                torch.save(representations, f'{save_path}/{dms}.pt')\n",
    "                # print(representations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config):\n",
    "    if config.model == 'ESM-1v':\n",
    "        esm_model = EsmModel.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{config.model_seed}')\n",
    "        tokenizer = EsmTokenizer.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{config.model_seed}')\n",
    "    elif config.model == 'ESM-2':\n",
    "        esm_model = EsmModel.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "        tokenizer = EsmTokenizer.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "    elif config.model == 'ESM-1b':\n",
    "        esm_model = EsmModel.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n",
    "        tokenizer = EsmTokenizer.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n",
    "    esm_model.eval()\n",
    "    # print(esm_model)\n",
    "    if torch.cuda.is_available() and not config.nogpu:\n",
    "        esm_model = esm_model.cuda()\n",
    "        print(\"Transferred model to GPU\")\n",
    "    if(config.csv_file):\n",
    "        data_df = pd.read_csv('../data/DMS_substitutions.csv')\n",
    "        dfset = Protein_Dataset(data_df,tokenizer=tokenizer)\n",
    "        dfloader = DataLoader(dfset, batch_size=config.batch_size, collate_fn=dfset.collate_fn, shuffle=False)\n",
    "    else:\n",
    "        print('no file!')\n",
    "    save_path = config.save_path\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    embed(esm_model,dfloader,save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm1b_t33_650M_UR50S and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/binyun/miniforge3/envs/esm/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred model to GPU\n",
      "Processing 1 of 4 batches (32 sequences)\n",
      "Processing 2 of 4 batches (32 sequences)\n",
      "Processing 3 of 4 batches (32 sequences)\n",
      "Processing 4 of 4 batches (32 sequences)\n",
      "Processing 5 of 4 batches (32 sequences)\n",
      "Processing 6 of 4 batches (32 sequences)\n",
      "Processing 7 of 4 batches (25 sequences)\n"
     ]
    }
   ],
   "source": [
    "run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xihe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

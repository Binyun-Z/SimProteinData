{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用ESM预训练模型提取特征向量\n",
    "参考：https://github.com/facebookresearch/esm/blob/c9c7d4f0fec964ce10c3e11dccec6c16edaa5144/scripts/extract.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EsmForMaskedLM, EsmTokenizer, BertModel\n",
    "from esm import Alphabet, FastaBatchedDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinExtractionParams:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model='ESM-1v',\n",
    "        EMB_LAYER = 33,\n",
    "        model_seed = 1,\n",
    "        fasta_file = None,\n",
    "        csv_file = '../data/DMS_substitutions.csv',\n",
    "        output_dir = None,\n",
    "        toks_per_batch=4096,\n",
    "        repr_layers=[-1],\n",
    "        include='mean',\n",
    "        truncation_seq_length=1022,\n",
    "        nogpu=False,\n",
    "    ):\n",
    "        self.model=model\n",
    "        self.model_seed = model_seed\n",
    "        self.EMB_LAYER = EMB_LAYER\n",
    "        self.fasta_file = fasta_file\n",
    "        self.csv_file = csv_file\n",
    "\n",
    "        # if not os.path.exists(output_dir):\n",
    "        #     os.makedirs(output_dir)\n",
    "        self.toks_per_batch = toks_per_batch\n",
    "        self.repr_layers = repr_layers\n",
    "        self.include = include\n",
    "        self.truncation_seq_length = truncation_seq_length\n",
    "        self.nogpu = nogpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = ProteinExtractionParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protein_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, sep_len=1024):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = sep_len\n",
    "        self.seq, self.attention_mask = tokenizer(list(self.df['target_seq']), padding='max_length',\n",
    "                                                  truncation=True,\n",
    "                                                  max_length=self.seq_len).values()\n",
    "        self.DMS_id = np.asarray(df['DMS_id'])\n",
    "        self.pid = np.asarray(df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.seq[idx], self.attention_mask[idx],self.DMS_id[idx],self.pid[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        seq = torch.tensor(np.array([u[0] for u in data]))\n",
    "        att_mask = torch.tensor(np.array([u[1] for u in data]))\n",
    "        DMS_id = [u[2] for u in data]\n",
    "        pid = torch.tensor(np.array([u[3] for u in data]))\n",
    "        return seq, att_mask, DMS_id,pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(model,data_loader,repr_layers=33,return_contacts=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(data_loader):\n",
    "\n",
    "            seq, mask, DMS_id,pid= data[0],data[1],data[2],data[3]\n",
    "            print(\n",
    "                f\"Processing {batch_idx + 1} of {len(data)} batches ({seq.size(0)} sequences)\"\n",
    "            )\n",
    "            if torch.cuda.is_available() and not config.nogpu:\n",
    "                seq = seq.to(device=\"cuda\", non_blocking=True)\n",
    "                mask = mask.to(device=\"cuda\", non_blocking=True)\n",
    "\n",
    "            out = model(seq,mask)\n",
    "\n",
    "            # logits = out[\"logits\"].to(device=\"cpu\")\n",
    "            # representations = {\n",
    "            #     layer: t.to(device=\"cpu\") for layer, t in out[\"representations\"].items()\n",
    "            # }\n",
    "            print(out)\n",
    "            print(out[\"logits\"].shape)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config):\n",
    "    if config.model == 'ESM-1v':\n",
    "        esm_model = EsmForMaskedLM.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{config.model_seed}')\n",
    "        tokenizer = EsmTokenizer.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{config.model_seed}')\n",
    "    elif config.model == 'ESM-2':\n",
    "        esm_model = EsmForMaskedLM.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "        tokenizer = EsmTokenizer.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "    elif config.model == 'ESM-1b':\n",
    "        esm_model = EsmForMaskedLM.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n",
    "        tokenizer = EsmTokenizer.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n",
    "    esm_model.eval()\n",
    "    # print(esm_model)\n",
    "    if torch.cuda.is_available() and not config.nogpu:\n",
    "        esm_model = esm_model.cuda()\n",
    "        print(\"Transferred model to GPU\")\n",
    "    if(config.csv_file):\n",
    "        data_df = pd.read_csv('../data/DMS_substitutions.csv')\n",
    "        dfset = Protein_Dataset(data_df,tokenizer=tokenizer)\n",
    "        dfloader = DataLoader(dfset, batch_size=32, collate_fn=dfset.collate_fn, shuffle=False)\n",
    "    else:\n",
    "        print('no file!')\n",
    "\n",
    "    embed(esm_model,dfloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/binyun/miniforge3/envs/esm/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred model to GPU\n",
      "Processing 1 of 4 batches (32 sequences)\n",
      "MaskedLMOutput(loss=None, logits=tensor([[[ 27.4595,  -9.7221,  -9.7196,  ...,  -9.4770,  -8.8551,  -9.5298],\n",
      "         [-11.7753, -19.3972, -19.4954,  ..., -15.4997, -14.7554, -19.3613],\n",
      "         [-14.4387, -20.4217, -20.3754,  ..., -15.5238, -15.7760, -20.6390],\n",
      "         ...,\n",
      "         [-14.0112, -18.7812, -18.7424,  ..., -15.5570, -15.5467, -18.8976],\n",
      "         [-13.7338, -18.7242, -18.5399,  ..., -15.8084, -16.0953, -18.9025],\n",
      "         [-16.1599, -19.2491, -19.1543,  ..., -15.8731, -15.9174, -19.3599]],\n",
      "\n",
      "        [[ 25.8212,  -4.4358,  -4.4236,  ...,  -7.9350,  -9.1862,  -4.3968],\n",
      "         [ -5.4564, -20.2427, -20.6580,  ..., -14.1852, -13.6468, -20.4660],\n",
      "         [-14.0237, -20.4926, -20.8519,  ..., -14.5333, -14.4374, -20.6440],\n",
      "         ...,\n",
      "         [-16.1606, -21.0762, -21.4961,  ..., -14.6801, -15.1779, -21.1792],\n",
      "         [-16.1606, -21.0762, -21.4961,  ..., -14.6801, -15.1779, -21.1792],\n",
      "         [-16.1606, -21.0762, -21.4961,  ..., -14.6801, -15.1779, -21.1792]],\n",
      "\n",
      "        [[ 22.7138,  -5.3532,  -5.3313,  ...,  -8.4995,  -8.4546,  -4.9772],\n",
      "         [ -9.5931, -19.9595, -20.2577,  ..., -14.8554, -13.7665, -19.7782],\n",
      "         [-10.8851, -19.2342, -19.7176,  ..., -13.0356, -12.3736, -19.7606],\n",
      "         ...,\n",
      "         [-15.5253, -22.7252, -22.5777,  ..., -15.3223, -15.5990, -22.5749],\n",
      "         [-15.5253, -22.7252, -22.5777,  ..., -15.3223, -15.5990, -22.5749],\n",
      "         [-15.5253, -22.7252, -22.5777,  ..., -15.3223, -15.5990, -22.5749]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 29.4139,  -5.4927,  -5.3567,  ...,  -8.9589,  -9.3290,  -5.5964],\n",
      "         [-11.3196, -18.2948, -18.4028,  ..., -15.3601, -14.5525, -18.4125],\n",
      "         [-13.7491, -19.0546, -19.0610,  ..., -15.6054, -15.8182, -19.2158],\n",
      "         ...,\n",
      "         [-14.2161, -18.7015, -18.9058,  ..., -15.6844, -15.6620, -18.6297],\n",
      "         [-12.7816, -18.2231, -18.3765,  ..., -15.3229, -15.2620, -18.2972],\n",
      "         [-15.4523, -18.6821, -18.7098,  ..., -15.7613, -15.8514, -18.7071]],\n",
      "\n",
      "        [[ 29.4139,  -5.4927,  -5.3567,  ...,  -8.9589,  -9.3290,  -5.5964],\n",
      "         [-11.3196, -18.2948, -18.4028,  ..., -15.3601, -14.5525, -18.4125],\n",
      "         [-13.7491, -19.0546, -19.0610,  ..., -15.6054, -15.8182, -19.2158],\n",
      "         ...,\n",
      "         [-14.2161, -18.7015, -18.9058,  ..., -15.6844, -15.6620, -18.6297],\n",
      "         [-12.7816, -18.2231, -18.3765,  ..., -15.3229, -15.2620, -18.2972],\n",
      "         [-15.4523, -18.6821, -18.7098,  ..., -15.7613, -15.8514, -18.7071]],\n",
      "\n",
      "        [[ 25.8170,  -8.8434,  -8.6782,  ...,  -9.0083,  -9.3968,  -8.4714],\n",
      "         [-10.7288, -20.3795, -20.4466,  ..., -15.6190, -14.7383, -20.3489],\n",
      "         [-11.6174, -21.2410, -21.5931,  ..., -15.7209, -15.7933, -20.9957],\n",
      "         ...,\n",
      "         [-16.1238, -19.9828, -19.9783,  ..., -15.6304, -15.7753, -19.9936],\n",
      "         [-14.4777, -19.5162, -19.6367,  ..., -15.4685, -15.6123, -19.7144],\n",
      "         [-15.4565, -19.9452, -19.9121,  ..., -15.8870, -16.0394, -20.0055]]],\n",
      "       device='cuda:0'), hidden_states=None, attentions=None)\n",
      "torch.Size([32, 1024, 33])\n"
     ]
    }
   ],
   "source": [
    "run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xihe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
